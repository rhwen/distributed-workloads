{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Upload the Model\n",
    "\n",
    "To upload the Llama model to s3-compatible storage so that you can deploy it the the model serving server."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Install the required packages and define a function for the upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: boto3 in /opt/app-root/lib/python3.9/site-packages (1.34.162)\n",
      "Requirement already satisfied: botocore in /opt/app-root/lib/python3.9/site-packages (1.34.162)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /opt/app-root/lib/python3.9/site-packages (from boto3) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.11.0,>=0.10.0 in /opt/app-root/lib/python3.9/site-packages (from boto3) (0.10.2)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /opt/app-root/lib/python3.9/site-packages (from botocore) (1.26.19)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /opt/app-root/lib/python3.9/site-packages (from botocore) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/app-root/lib/python3.9/site-packages (from python-dateutil<3.0.0,>=2.1->botocore) (1.16.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.2.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install boto3 botocore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import boto3\n",
    "import botocore\n",
    "\n",
    "aws_access_key_id = 'minio'#os.environ.get('AWS_ACCESS_KEY_ID')\n",
    "aws_secret_access_key = 'minio123'#os.environ.get('AWS_SECRET_ACCESS_KEY')\n",
    "endpoint_url = 'http://minio.ic-shared-minio.svc:9000'#os.environ.get('AWS_S3_ENDPOINT')\n",
    "region_name = 'us-east-1'#os.environ.get('AWS_DEFAULT_REGION')\n",
    "bucket_name = 'llama-2-weights'#os.environ.get('AWS_S3_BUCKET')\n",
    "\n",
    "if not all([aws_access_key_id, aws_secret_access_key, endpoint_url, region_name, bucket_name]):\n",
    "    raise ValueError(\"One or data connection variables are empty.  \"\n",
    "                     \"Please check your data connection to an S3 bucket.\")\n",
    "\n",
    "session = boto3.session.Session(aws_access_key_id=aws_access_key_id,\n",
    "                                aws_secret_access_key=aws_secret_access_key)\n",
    "\n",
    "s3_resource = session.resource(\n",
    "    's3',\n",
    "    config=botocore.client.Config(signature_version='s3v4'),\n",
    "    endpoint_url=endpoint_url,\n",
    "    region_name=region_name)\n",
    "\n",
    "bucket = s3_resource.Bucket(bucket_name)\n",
    "\n",
    "\n",
    "def upload_directory_to_s3(local_directory, s3_prefix):\n",
    "    num_files = 0\n",
    "    for root, dirs, files in os.walk(local_directory):\n",
    "        for filename in files:\n",
    "            file_path = os.path.join(root, filename)\n",
    "            relative_path = os.path.relpath(file_path, local_directory)\n",
    "            s3_key = os.path.join(s3_prefix, relative_path)\n",
    "            print(f\"{file_path} -> {s3_key}\")\n",
    "            bucket.upload_file(file_path, s3_key)\n",
    "            num_files += 1\n",
    "    return num_files\n",
    "\n",
    "def convert_model_id(model_id: str) -> str:\n",
    "    return f\"/models--{model_id.replace('/', '--')}\"\n",
    "\n",
    "def list_objects(prefix):\n",
    "    filter = bucket.objects.filter(Prefix=prefix)\n",
    "    for obj in filter.all():\n",
    "        print(obj.key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Verify the upload\n",
    "\n",
    "In your S3 bucket, under the `models` upload prefix, run the `list_object` command. \n",
    "\n",
    "The `meta-llama/Llama-3.2-1B` model will convert to `models--meta-llama--Llama-3.2-1B` and  upload to the `llama-2-weights` bucket. \n",
    "\n",
    "If this is the first time running the code, this cell will have no output.\n",
    "\n",
    "If you've already uploaded your model, you should see this output: `models--meta-llama--Llama-3.2-1B/**`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "list_objects('models')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Upload and check again"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the function to upload the `models` folder in a rescursive fashion:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/tmp/Llama-3.2-1B/.gitattributes -> /models--meta-llama--Llama-3.2-1B/.gitattributes\n",
      "/tmp/Llama-3.2-1B/tokenizer_config.json -> /models--meta-llama--Llama-3.2-1B/tokenizer_config.json\n",
      "/tmp/Llama-3.2-1B/tokenizer.json -> /models--meta-llama--Llama-3.2-1B/tokenizer.json\n",
      "/tmp/Llama-3.2-1B/config.json -> /models--meta-llama--Llama-3.2-1B/config.json\n",
      "/tmp/Llama-3.2-1B/USE_POLICY.md -> /models--meta-llama--Llama-3.2-1B/USE_POLICY.md\n",
      "/tmp/Llama-3.2-1B/README.md -> /models--meta-llama--Llama-3.2-1B/README.md\n",
      "/tmp/Llama-3.2-1B/model.safetensors -> /models--meta-llama--Llama-3.2-1B/model.safetensors\n",
      "/tmp/Llama-3.2-1B/special_tokens_map.json -> /models--meta-llama--Llama-3.2-1B/special_tokens_map.json\n",
      "/tmp/Llama-3.2-1B/generation_config.json -> /models--meta-llama--Llama-3.2-1B/generation_config.json\n",
      "/tmp/Llama-3.2-1B/LICENSE.txt -> /models--meta-llama--Llama-3.2-1B/LICENSE.txt\n",
      "/tmp/Llama-3.2-1B/original/params.json -> /models--meta-llama--Llama-3.2-1B/original/params.json\n",
      "/tmp/Llama-3.2-1B/original/tokenizer.model -> /models--meta-llama--Llama-3.2-1B/original/tokenizer.model\n",
      "/tmp/Llama-3.2-1B/original/consolidated.00.pth -> /models--meta-llama--Llama-3.2-1B/original/consolidated.00.pth\n",
      "/tmp/Llama-3.2-1B/.cache/huggingface/.gitignore -> /models--meta-llama--Llama-3.2-1B/.cache/huggingface/.gitignore\n",
      "/tmp/Llama-3.2-1B/.cache/huggingface/download/model.safetensors.metadata -> /models--meta-llama--Llama-3.2-1B/.cache/huggingface/download/model.safetensors.metadata\n",
      "/tmp/Llama-3.2-1B/.cache/huggingface/download/special_tokens_map.json.lock -> /models--meta-llama--Llama-3.2-1B/.cache/huggingface/download/special_tokens_map.json.lock\n",
      "/tmp/Llama-3.2-1B/.cache/huggingface/download/special_tokens_map.json.metadata -> /models--meta-llama--Llama-3.2-1B/.cache/huggingface/download/special_tokens_map.json.metadata\n",
      "/tmp/Llama-3.2-1B/.cache/huggingface/download/README.md.metadata -> /models--meta-llama--Llama-3.2-1B/.cache/huggingface/download/README.md.metadata\n",
      "/tmp/Llama-3.2-1B/.cache/huggingface/download/tokenizer.json.metadata -> /models--meta-llama--Llama-3.2-1B/.cache/huggingface/download/tokenizer.json.metadata\n",
      "/tmp/Llama-3.2-1B/.cache/huggingface/download/.gitattributes.lock -> /models--meta-llama--Llama-3.2-1B/.cache/huggingface/download/.gitattributes.lock\n",
      "/tmp/Llama-3.2-1B/.cache/huggingface/download/config.json.lock -> /models--meta-llama--Llama-3.2-1B/.cache/huggingface/download/config.json.lock\n",
      "/tmp/Llama-3.2-1B/.cache/huggingface/download/LICENSE.txt.lock -> /models--meta-llama--Llama-3.2-1B/.cache/huggingface/download/LICENSE.txt.lock\n",
      "/tmp/Llama-3.2-1B/.cache/huggingface/download/generation_config.json.metadata -> /models--meta-llama--Llama-3.2-1B/.cache/huggingface/download/generation_config.json.metadata\n",
      "/tmp/Llama-3.2-1B/.cache/huggingface/download/README.md.lock -> /models--meta-llama--Llama-3.2-1B/.cache/huggingface/download/README.md.lock\n",
      "/tmp/Llama-3.2-1B/.cache/huggingface/download/tokenizer_config.json.lock -> /models--meta-llama--Llama-3.2-1B/.cache/huggingface/download/tokenizer_config.json.lock\n",
      "/tmp/Llama-3.2-1B/.cache/huggingface/download/USE_POLICY.md.metadata -> /models--meta-llama--Llama-3.2-1B/.cache/huggingface/download/USE_POLICY.md.metadata\n",
      "/tmp/Llama-3.2-1B/.cache/huggingface/download/generation_config.json.lock -> /models--meta-llama--Llama-3.2-1B/.cache/huggingface/download/generation_config.json.lock\n",
      "/tmp/Llama-3.2-1B/.cache/huggingface/download/tokenizer.json.lock -> /models--meta-llama--Llama-3.2-1B/.cache/huggingface/download/tokenizer.json.lock\n",
      "/tmp/Llama-3.2-1B/.cache/huggingface/download/config.json.metadata -> /models--meta-llama--Llama-3.2-1B/.cache/huggingface/download/config.json.metadata\n",
      "/tmp/Llama-3.2-1B/.cache/huggingface/download/USE_POLICY.md.lock -> /models--meta-llama--Llama-3.2-1B/.cache/huggingface/download/USE_POLICY.md.lock\n",
      "/tmp/Llama-3.2-1B/.cache/huggingface/download/.gitattributes.metadata -> /models--meta-llama--Llama-3.2-1B/.cache/huggingface/download/.gitattributes.metadata\n",
      "/tmp/Llama-3.2-1B/.cache/huggingface/download/tokenizer_config.json.metadata -> /models--meta-llama--Llama-3.2-1B/.cache/huggingface/download/tokenizer_config.json.metadata\n",
      "/tmp/Llama-3.2-1B/.cache/huggingface/download/model.safetensors.lock -> /models--meta-llama--Llama-3.2-1B/.cache/huggingface/download/model.safetensors.lock\n",
      "/tmp/Llama-3.2-1B/.cache/huggingface/download/LICENSE.txt.metadata -> /models--meta-llama--Llama-3.2-1B/.cache/huggingface/download/LICENSE.txt.metadata\n",
      "/tmp/Llama-3.2-1B/.cache/huggingface/download/original/consolidated.00.pth.lock -> /models--meta-llama--Llama-3.2-1B/.cache/huggingface/download/original/consolidated.00.pth.lock\n",
      "/tmp/Llama-3.2-1B/.cache/huggingface/download/original/tokenizer.model.lock -> /models--meta-llama--Llama-3.2-1B/.cache/huggingface/download/original/tokenizer.model.lock\n",
      "/tmp/Llama-3.2-1B/.cache/huggingface/download/original/params.json.lock -> /models--meta-llama--Llama-3.2-1B/.cache/huggingface/download/original/params.json.lock\n",
      "/tmp/Llama-3.2-1B/.cache/huggingface/download/original/tokenizer.model.metadata -> /models--meta-llama--Llama-3.2-1B/.cache/huggingface/download/original/tokenizer.model.metadata\n",
      "/tmp/Llama-3.2-1B/.cache/huggingface/download/original/consolidated.00.pth.metadata -> /models--meta-llama--Llama-3.2-1B/.cache/huggingface/download/original/consolidated.00.pth.metadata\n",
      "/tmp/Llama-3.2-1B/.cache/huggingface/download/original/params.json.metadata -> /models--meta-llama--Llama-3.2-1B/.cache/huggingface/download/original/params.json.metadata\n"
     ]
    }
   ],
   "source": [
    "local_models_directory = \"/tmp/Llama-3.2-1B/\"\n",
    "model_id = \"meta-llama/Llama-3.2-1B\"\n",
    "s3_prefix = convert_model_id(model_id)\n",
    "\n",
    "if not os.path.isdir(local_models_directory):\n",
    "    raise ValueError(f\"The directory '{local_models_directory}' does not exist.\")\n",
    "\n",
    "num_files = upload_directory_to_s3(local_models_directory, s3_prefix)\n",
    "\n",
    "if num_files == 0:\n",
    "    raise ValueError(\"No files uploaded.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "To confirm this worked, run the `list_objects` function again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models--meta-llama--Llama-3.2-1B/.cache/huggingface/.gitignore\n",
      "models--meta-llama--Llama-3.2-1B/.cache/huggingface/download/.gitattributes.lock\n",
      "models--meta-llama--Llama-3.2-1B/.cache/huggingface/download/.gitattributes.metadata\n",
      "models--meta-llama--Llama-3.2-1B/.cache/huggingface/download/LICENSE.txt.lock\n",
      "models--meta-llama--Llama-3.2-1B/.cache/huggingface/download/LICENSE.txt.metadata\n",
      "models--meta-llama--Llama-3.2-1B/.cache/huggingface/download/README.md.lock\n",
      "models--meta-llama--Llama-3.2-1B/.cache/huggingface/download/README.md.metadata\n",
      "models--meta-llama--Llama-3.2-1B/.cache/huggingface/download/USE_POLICY.md.lock\n",
      "models--meta-llama--Llama-3.2-1B/.cache/huggingface/download/USE_POLICY.md.metadata\n",
      "models--meta-llama--Llama-3.2-1B/.cache/huggingface/download/config.json.lock\n",
      "models--meta-llama--Llama-3.2-1B/.cache/huggingface/download/config.json.metadata\n",
      "models--meta-llama--Llama-3.2-1B/.cache/huggingface/download/generation_config.json.lock\n",
      "models--meta-llama--Llama-3.2-1B/.cache/huggingface/download/generation_config.json.metadata\n",
      "models--meta-llama--Llama-3.2-1B/.cache/huggingface/download/model.safetensors.lock\n",
      "models--meta-llama--Llama-3.2-1B/.cache/huggingface/download/model.safetensors.metadata\n",
      "models--meta-llama--Llama-3.2-1B/.cache/huggingface/download/original/consolidated.00.pth.lock\n",
      "models--meta-llama--Llama-3.2-1B/.cache/huggingface/download/original/consolidated.00.pth.metadata\n",
      "models--meta-llama--Llama-3.2-1B/.cache/huggingface/download/original/params.json.lock\n",
      "models--meta-llama--Llama-3.2-1B/.cache/huggingface/download/original/params.json.metadata\n",
      "models--meta-llama--Llama-3.2-1B/.cache/huggingface/download/original/tokenizer.model.lock\n",
      "models--meta-llama--Llama-3.2-1B/.cache/huggingface/download/original/tokenizer.model.metadata\n",
      "models--meta-llama--Llama-3.2-1B/.cache/huggingface/download/special_tokens_map.json.lock\n",
      "models--meta-llama--Llama-3.2-1B/.cache/huggingface/download/special_tokens_map.json.metadata\n",
      "models--meta-llama--Llama-3.2-1B/.cache/huggingface/download/tokenizer.json.lock\n",
      "models--meta-llama--Llama-3.2-1B/.cache/huggingface/download/tokenizer.json.metadata\n",
      "models--meta-llama--Llama-3.2-1B/.cache/huggingface/download/tokenizer_config.json.lock\n",
      "models--meta-llama--Llama-3.2-1B/.cache/huggingface/download/tokenizer_config.json.metadata\n",
      "models--meta-llama--Llama-3.2-1B/.gitattributes\n",
      "models--meta-llama--Llama-3.2-1B/LICENSE.txt\n",
      "models--meta-llama--Llama-3.2-1B/README.md\n",
      "models--meta-llama--Llama-3.2-1B/USE_POLICY.md\n",
      "models--meta-llama--Llama-3.2-1B/config.json\n",
      "models--meta-llama--Llama-3.2-1B/generation_config.json\n",
      "models--meta-llama--Llama-3.2-1B/model.safetensors\n",
      "models--meta-llama--Llama-3.2-1B/original/consolidated.00.pth\n",
      "models--meta-llama--Llama-3.2-1B/original/params.json\n",
      "models--meta-llama--Llama-3.2-1B/original/tokenizer.model\n",
      "models--meta-llama--Llama-3.2-1B/special_tokens_map.json\n",
      "models--meta-llama--Llama-3.2-1B/tokenizer.json\n",
      "models--meta-llama--Llama-3.2-1B/tokenizer_config.json\n"
     ]
    }
   ],
   "source": [
    "list_objects(\"models\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next Step\n",
    "\n",
    "Now that you've saved the model to s3 storage, you can refer to the model by using the same data connection to serve the model as an API.\n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
